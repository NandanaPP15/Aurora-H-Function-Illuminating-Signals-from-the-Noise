# -*- coding: utf-8 -*-
"""last all .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n4LqA40MxsaKHnFnhMR2H4faYc3Ug6eh

H FUNCTION FILTER
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import fft, ifft, fftfreq
from google.colab import files
import soundfile as sf
import io

# ---------------------------------------------------
# Load WAV Audio
# ---------------------------------------------------
def load_audio():
    uploaded = files.upload()
    name = list(uploaded.keys())[0]
    data, fs = sf.read(io.BytesIO(uploaded[name]))

    if data.ndim > 1:  # stereo → mono
        data = np.mean(data, axis=1)

    data = data.astype(float)
    data = (data - np.mean(data)) / np.std(data)  # normalize
    return data, fs

# ---------------------------------------------------
# FAST H-Filter (NO optimization)
# tuned params for speech audio
# ---------------------------------------------------
def h_filter(signal, fs, cutoff=3800):
    alpha = 2.3
    beta  = 1.4
    gamma = 0.12
    delta = 0.35

    n = len(signal)
    freqs = fftfreq(n, 1/fs)
    fft_vals = fft(signal)

    H = 1 / (1 + (np.abs(freqs)/cutoff)**alpha)**beta
    H *= np.exp(-gamma * (np.abs(freqs)/cutoff))
    H **= (1 + delta)
    H /= np.max(H)   # normalize

    filtered = np.real(ifft(fft_vals * H))
    return filtered, H, freqs

# ---------------------------------------------------
# Main Processing
# ---------------------------------------------------
def process_audio():
    print("Upload your NOISY voice file (.wav)")
    noisy, fs = load_audio()

    print("Removing noise using fast H-filter...")
    filtered, H, freqs = h_filter(noisy, fs)

    # Plot before/after
    plt.figure(figsize=(14,4))
    plt.plot(noisy, alpha=0.45, label="Noisy")
    plt.plot(filtered, alpha=0.9, label="Cleaned")
    plt.title("Noisy vs Cleaned Voice (H-filter)")
    plt.legend()
    plt.show()

    # Save clean audio
    out = filtered / np.max(np.abs(filtered))
    sf.write("clean_voice.wav", out, fs)
    print("Download your cleaned voice:")
    files.download("clean_voice.wav")

# ---------------------------------------------------
if __name__ == "__main__":
    process_audio()

import numpy as np
import matplotlib.pyplot as plt
import librosa
import soundfile as sf
from scipy.fft import fft, ifft, fftfreq
from google.colab import files
import io

# ---------------------------------------------------
# Load audio
# ---------------------------------------------------
def load_audio(prompt="Upload audio (.wav/.opus)"):
    print(prompt)
    uploaded = files.upload()
    name = list(uploaded.keys())[0]
    data, fs = librosa.load(io.BytesIO(uploaded[name]), sr=None, mono=True)
    data = data.astype(float)
    return data, fs, name

# ---------------------------------------------------
# Your original H-function filter
# ---------------------------------------------------
def h_filter_original(signal, fs, alpha=2.3, beta=1.4, gamma=0.12, delta=0.35, cutoff_freq=3800):
    n = len(signal)
    freqs = fftfreq(n, 1/fs)
    fft_vals = fft(signal)

    # Original H-function formula
    H = 1 / (1 + (np.abs(freqs)/cutoff_freq)**alpha)**beta
    H *= np.exp(-gamma * (np.abs(freqs)/cutoff_freq))
    H = H ** (1 + delta)
    H /= np.max(H)

    filtered_signal = np.real(ifft(fft_vals * H))
    return filtered_signal, H, freqs

# ---------------------------------------------------
# High-pass / low-pass pre-filter to remove hum/hiss
# ---------------------------------------------------
def bandpass_preprocess(signal, fs, low_cut=80, high_cut=7000):
    n = len(signal)
    freqs = fftfreq(n, 1/fs)
    fft_vals = fft(signal)
    H_bp = np.ones(n)
    H_bp[np.abs(freqs) < low_cut] = 0     # Remove rumble
    H_bp[np.abs(freqs) > high_cut] = 0    # Remove high-frequency hiss
    filtered = np.real(ifft(fft_vals * H_bp))
    return filtered

# ---------------------------------------------------
# Optional soft spectral thresholding to reduce residual noise
# ---------------------------------------------------
def spectral_soft_threshold(signal, fs, threshold_db=-40):
    fft_vals = fft(signal)
    magnitude = np.abs(fft_vals)
    phase = np.angle(fft_vals)
    mag_db = 20 * np.log10(magnitude + 1e-10)
    mag_db = np.maximum(mag_db, threshold_db)   # suppress below threshold
    magnitude_new = 10 ** (mag_db / 20)
    return np.real(ifft(magnitude_new * np.exp(1j * phase)))

# ---------------------------------------------------
# Compute aligned SNR
# ---------------------------------------------------
def calculate_snr_aligned(clean, noisy):
    clean = clean - np.mean(clean)
    noisy = noisy - np.mean(noisy)
    corr = np.correlate(noisy, clean, mode='full')
    delay = corr.argmax() - (len(clean) - 1)

    if delay > 0:
        noisy_aligned = noisy[delay:]
        clean_aligned = clean[:len(noisy_aligned)]
    elif delay < 0:
        clean_aligned = clean[-delay:]
        noisy_aligned = noisy[:len(clean_aligned)]
    else:
        noisy_aligned = noisy
        clean_aligned = clean

    min_len = min(len(clean_aligned), len(noisy_aligned))
    clean_aligned = clean_aligned[:min_len]
    noisy_aligned = noisy_aligned[:min_len]

    noise = noisy_aligned - clean_aligned
    s_power = np.mean(clean_aligned**2)
    n_power = np.mean(noise**2)
    if n_power < 1e-15: return np.nan
    snr = 10 * np.log10(s_power / n_power)
    return snr

# ---------------------------------------------------
# Main processing
# ---------------------------------------------------
def process_audio():
    # Upload clean & noisy files
    clean, fs_clean, _ = load_audio("Upload CLEAN voice (.wav/.opus)")
    noisy, fs_noisy, _ = load_audio("Upload NOISY voice (.wav/.opus)")

    # Resample to same rate
    target_fs = 16000
    clean = librosa.resample(clean, orig_sr=fs_clean, target_sr=target_fs)
    noisy = librosa.resample(noisy, orig_sr=fs_noisy, target_sr=target_fs)
    fs = target_fs

    # 1️⃣ Pre-filter to remove rumble/hiss
    noisy_bp = bandpass_preprocess(noisy, fs)

    # 2️⃣ Apply original H-function filter
    filtered, H, freqs = h_filter_original(noisy_bp, fs)

    # 3️⃣ Optional spectral soft thresholding (improves residual noise)
    filtered = spectral_soft_threshold(filtered, fs, threshold_db=-45)

    # 4️⃣ Match amplitude to clean RMS
    rms_clean = np.sqrt(np.mean(clean**2))
    rms_filtered = np.sqrt(np.mean(filtered**2))
    filtered *= (rms_clean / (rms_filtered + 1e-10))

    # 5️⃣ Compute SNR improvement
    snr_before = calculate_snr_aligned(clean, noisy)
    snr_after  = calculate_snr_aligned(clean, filtered)

    print(f"\nSNR Before Filtering : {snr_before:.4f} dB")
    print(f"SNR After Filtering  : {snr_after:.4f} dB")
    print(f"Improvement          : {snr_after - snr_before:.4f} dB")

    # 6️⃣ Plot waveforms
    plt.figure(figsize=(14,4))
    plt.plot(clean, alpha=0.6, label="Clean")
    plt.plot(noisy, alpha=0.4, label="Noisy")
    plt.plot(filtered, alpha=0.9, label="Filtered")
    plt.title("Clean vs Noisy vs Filtered Audio (Improved H-function)")
    plt.legend()
    plt.show()

    # 7️⃣ Plot H-function frequency response
    plt.figure(figsize=(14,4))
    plt.plot(freqs[:len(freqs)//2], H[:len(H)//2])
    plt.title("Original H-function Frequency Response")
    plt.xlabel("Frequency (Hz)")
    plt.ylabel("Gain")
    plt.show()

    # 8️⃣ Save filtered audio
    filtered_norm = filtered / np.max(np.abs(filtered)) * 0.99
    sf.write("improved_denoised_voice.wav", filtered_norm, fs)
    print("Download your improved filtered voice:")
    files.download("improved_denoised_voice.wav")

# ---------------------------------------------------
if __name__ == "__main__":
    process_audio()

"""ALL FILTERS IN REAL WORLD AUDIO

"""

import numpy as np
import matplotlib.pyplot as plt
import librosa
import soundfile as sf
from scipy.fft import fft, ifft, fftfreq
from scipy.signal import wiener, butter, filtfilt, iirnotch, correlate
import pywt
from google.colab import files
import io

# -------------------- Load Audio --------------------
def load_audio(prompt="Upload audio (.wav/.opus)"):
    print(prompt)
    uploaded = files.upload()
    name = list(uploaded.keys())[0]
    data, fs = librosa.load(io.BytesIO(uploaded[name]), sr=None, mono=True)
    data = data.astype(float)
    return data, fs, name

# -------------------- Original H-function Filter --------------------
def h_filter_original(signal, fs, alpha=2.3, beta=1.4, gamma=0.12, delta=0.35, cutoff_freq=3800):
    n = len(signal)
    freqs = fftfreq(n, 1/fs)
    fft_vals = fft(signal)
    H = 1 / (1 + (np.abs(freqs)/cutoff_freq)**alpha)**beta
    H *= np.exp(-gamma * (np.abs(freqs)/cutoff_freq))
    H = H ** (1 + delta)
    H /= np.max(H)
    filtered_signal = np.real(ifft(fft_vals * H))
    return filtered_signal, H, freqs

# -------------------- Bandpass Filter --------------------
def bandpass_filter(signal, fs, lowcut=80, highcut=7000, order=4):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    y = filtfilt(b, a, signal)
    return y

# -------------------- Notch Filter --------------------
def notch_filter(signal, fs, freq=50.0, Q=30):
    b, a = iirnotch(freq, Q, fs)
    y = filtfilt(b, a, signal)
    return y

# -------------------- Wiener Filter --------------------
def wiener_filter(signal, mysize=29):
    return wiener(signal, mysize=mysize)

# -------------------- Wavelet Denoising --------------------
def wavelet_denoise(signal, wavelet='db8', level=4):
    coeffs = pywt.wavedec(signal, wavelet, level=level)
    sigma = np.median(np.abs(coeffs[-level])) / 0.6745
    uthresh = sigma * np.sqrt(2 * np.log(len(signal)))
    coeffs_thresh = [pywt.threshold(c, value=uthresh, mode='soft') for c in coeffs]
    return pywt.waverec(coeffs_thresh, wavelet)

# -------------------- Matched Filter --------------------
def matched_filter(noisy, reference):
    corr = correlate(noisy, reference, mode='same')
    corr /= np.max(np.abs(corr))
    return corr

# -------------------- SNR Calculation --------------------
def calculate_snr_aligned(clean, noisy):
    clean = clean - np.mean(clean)
    noisy = noisy - np.mean(noisy)
    corr = np.correlate(noisy, clean, mode='full')
    delay = corr.argmax() - (len(clean) - 1)
    if delay > 0:
        noisy_aligned = noisy[delay:]
        clean_aligned = clean[:len(noisy_aligned)]
    elif delay < 0:
        clean_aligned = clean[-delay:]
        noisy_aligned = noisy[:len(clean_aligned)]
    else:
        noisy_aligned = noisy
        clean_aligned = clean
    min_len = min(len(clean_aligned), len(noisy_aligned))
    clean_aligned = clean_aligned[:min_len]
    noisy_aligned = noisy_aligned[:min_len]
    noise = noisy_aligned - clean_aligned
    s_power = np.mean(clean_aligned**2)
    n_power = np.mean(noise**2)
    if n_power < 1e-15: return np.nan
    return 10 * np.log10(s_power / n_power)

# -------------------- Main Processing --------------------
def process_audio():
    # Upload clean & noisy audio
    clean, fs_clean, _ = load_audio("Upload CLEAN voice (.wav/.opus)")
    noisy, fs_noisy, _ = load_audio("Upload NOISY voice (.wav/.opus)")

    # Resample to same rate
    target_fs = 16000
    clean = librosa.resample(y=clean, orig_sr=fs_clean, target_sr=target_fs)
    noisy = librosa.resample(y=noisy, orig_sr=fs_noisy, target_sr=target_fs)
    fs = target_fs

    # -------------------- Apply Filters Independently --------------------
    results = {}

    results['H-filter'], _, _ = h_filter_original(noisy, fs)
    results['Bandpass'] = bandpass_filter(noisy, fs)
    results['Notch'] = notch_filter(noisy, fs)
    results['Wiener'] = wiener_filter(noisy)
    results['Wavelet'] = wavelet_denoise(noisy)
    results['Matched'] = matched_filter(noisy, clean)

    # -------------------- Evaluate SNR and Save --------------------
    snr_scores = {}
    print("\nSNR values for each filter method:")
    print("{:<20s} {:>10s}".format("Method", "SNR (dB)"))
    print("-"*32)

    for key, sig in results.items():
        # RMS normalization to match clean
        rms_clean = np.sqrt(np.mean(clean**2))
        rms_sig = np.sqrt(np.mean(sig**2))
        sig *= rms_clean / (rms_sig + 1e-10)

        # Calculate SNR
        snr = calculate_snr_aligned(clean, sig)
        snr_scores[key] = snr

        # Print SNR
        print("{:<20s} {:>10.2f}".format(key, snr))

        # Save audio
        fname = f"{key.replace(' ','_')}_denoised.wav"
        sf.write(fname, sig / np.max(np.abs(sig)) * 0.99, fs)
        files.download(fname)

    # -------------------- Best SNR --------------------
    best_method = max(snr_scores, key=snr_scores.get)
    best_signal = results[best_method]
    best_signal_norm = best_signal / np.max(np.abs(best_signal)) * 0.99
    sf.write("best_denoised_voice.wav", best_signal_norm, fs)
    print(f"\nBest method: {best_method} with SNR = {snr_scores[best_method]:.2f} dB")
    files.download("best_denoised_voice.wav")

    # -------------------- Plot All Signals --------------------
    plt.figure(figsize=(14,6))
    plt.plot(clean, alpha=0.6, label="Clean")
    plt.plot(noisy, alpha=0.3, label="Noisy")
    for key, sig in results.items():
        plt.plot(sig, alpha=0.6, label=f"{key} (SNR={snr_scores[key]:.1f} dB)")
    plt.title("Clean vs Noisy vs Filtered Audio Signals")
    plt.legend()
    plt.show()

# -------------------- Run --------------------
if __name__ == "__main__":
    process_audio()

import numpy as np
import matplotlib.pyplot as plt
import librosa
import soundfile as sf
from scipy.fft import fft, ifft, fftfreq
from scipy.signal import wiener, butter, filtfilt, iirnotch, correlate
import pywt
from google.colab import files
import io

# -------------------- Load Audio --------------------
def load_audio(prompt="Upload audio (.wav/.opus)"):
    print(prompt)
    uploaded = files.upload()
    name = list(uploaded.keys())[0]
    data, fs = librosa.load(io.BytesIO(uploaded[name]), sr=None, mono=True)
    data = data.astype(float)
    return data, fs, name

# -------------------- Original H-function Filter --------------------
def h_filter_original(signal, fs, alpha=2.3, beta=1.4, gamma=0.12, delta=0.35, cutoff_freq=3800):
    n = len(signal)
    freqs = fftfreq(n, 1/fs)
    fft_vals = fft(signal)
    H = 1 / (1 + (np.abs(freqs)/cutoff_freq)**alpha)**beta
    H *= np.exp(-gamma * (np.abs(freqs)/cutoff_freq))
    H = H ** (1 + delta)
    H /= np.max(H)
    filtered_signal = np.real(ifft(fft_vals * H))
    return filtered_signal, H, freqs

# -------------------- Bandpass Filter --------------------
def bandpass_filter(signal, fs, lowcut=80, highcut=7000, order=4):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    y = filtfilt(b, a, signal)
    return y

# -------------------- Notch Filter --------------------
def notch_filter(signal, fs, freq=50.0, Q=30):
    b, a = iirnotch(freq, Q, fs)
    y = filtfilt(b, a, signal)
    return y

# -------------------- Wiener Filter --------------------
def wiener_filter(signal, mysize=29):
    return wiener(signal, mysize=mysize)

# -------------------- Wavelet Denoising --------------------
def wavelet_denoise(signal, wavelet='db8', level=4):
    coeffs = pywt.wavedec(signal, wavelet, level=level)
    sigma = np.median(np.abs(coeffs[-level])) / 0.6745
    uthresh = sigma * np.sqrt(2 * np.log(len(signal)))
    coeffs_thresh = [pywt.threshold(c, value=uthresh, mode='soft') for c in coeffs]
    return pywt.waverec(coeffs_thresh, wavelet)

# -------------------- Matched Filter --------------------
def matched_filter(noisy, reference):
    corr = correlate(noisy, reference, mode='same')
    corr /= np.max(np.abs(corr))
    return corr

# -------------------- SNR Calculation --------------------
def calculate_snr_aligned(clean, noisy):
    clean = clean - np.mean(clean)
    noisy = noisy - np.mean(noisy)
    corr = np.correlate(noisy, clean, mode='full')
    delay = corr.argmax() - (len(clean) - 1)
    if delay > 0:
        noisy_aligned = noisy[delay:]
        clean_aligned = clean[:len(noisy_aligned)]
    elif delay < 0:
        clean_aligned = clean[-delay:]
        noisy_aligned = noisy[:len(clean_aligned)]
    else:
        noisy_aligned = noisy
        clean_aligned = clean
    min_len = min(len(clean_aligned), len(noisy_aligned))
    clean_aligned = clean_aligned[:min_len]
    noisy_aligned = noisy_aligned[:min_len]
    noise = noisy_aligned - clean_aligned
    s_power = np.mean(clean_aligned**2)
    n_power = np.mean(noise**2)
    if n_power < 1e-15: return np.nan
    return 10 * np.log10(s_power / n_power)

# -------------------- Main Processing --------------------
def process_audio():
    # Upload clean & noisy audio
    clean, fs_clean, _ = load_audio("Upload CLEAN voice (.wav/.opus)")
    noisy, fs_noisy, _ = load_audio("Upload NOISY voice (.wav/.opus)")

    # Resample to same rate
    target_fs = 16000
    clean = librosa.resample(y=clean, orig_sr=fs_clean, target_sr=target_fs)
    noisy = librosa.resample(y=noisy, orig_sr=fs_noisy, target_sr=target_fs)
    fs = target_fs

    # -------------------- Apply Filters Independently --------------------
    results = {}

    results['H-filter'], _, _ = h_filter_original(noisy, fs)
    results['Bandpass'] = bandpass_filter(noisy, fs)
    results['Notch'] = notch_filter(noisy, fs)
    results['Wiener'] = wiener_filter(noisy)
    results['Wavelet'] = wavelet_denoise(noisy)
    results['Matched'] = matched_filter(noisy, clean)

    # -------------------- Evaluate SNR and Save --------------------
    snr_scores = {}
    print("\nSNR values for each filter method:")
    print("{:<20s} {:>10s}".format("Method", "SNR (dB)"))
    print("-"*32)

    for key, sig in results.items():
        # RMS normalization to match clean
        rms_clean = np.sqrt(np.mean(clean**2))
        rms_sig = np.sqrt(np.mean(sig**2))
        sig *= rms_clean / (rms_sig + 1e-10)

        # Calculate SNR
        snr = calculate_snr_aligned(clean, sig)
        snr_scores[key] = snr

        # Print SNR
        print("{:<20s} {:>10.2f}".format(key, snr))

        # Save audio
        fname = f"{key.replace(' ','_')}_denoised.wav"
        sf.write(fname, sig / np.max(np.abs(sig)) * 0.99, fs)
        files.download(fname)

    # -------------------- Best SNR --------------------
    best_method = max(snr_scores, key=snr_scores.get)
    best_signal = results[best_method]
    best_signal_norm = best_signal / np.max(np.abs(best_signal)) * 0.99
    sf.write("best_denoised_voice.wav", best_signal_norm, fs)
    print(f"\nBest method: {best_method} with SNR = {snr_scores[best_method]:.2f} dB")
    files.download("best_denoised_voice.wav")

    # -------------------- Plot All Signals --------------------
    plt.figure(figsize=(14,6))
    plt.plot(clean, alpha=0.6, label="Clean")
    plt.plot(noisy, alpha=0.3, label="Noisy")
    for key, sig in results.items():
        plt.plot(sig, alpha=0.6, label=f"{key} (SNR={snr_scores[key]:.1f} dB)")
    plt.title("Clean vs Noisy vs Filtered Audio Signals")
    plt.legend()
    plt.show()

# -------------------- Run --------------------
if __name__ == "__main__":
    process_audio()

import numpy as np
import matplotlib.pyplot as plt
import librosa
import soundfile as sf
from scipy.fft import fft, ifft, fftfreq
from scipy.signal import wiener, butter, filtfilt, iirnotch, correlate
import pywt
from google.colab import files
import io

# -------------------- Load Audio --------------------
def load_audio(prompt="Upload audio (.wav/.opus)"):
    print(prompt)
    uploaded = files.upload()
    name = list(uploaded.keys())[0]
    data, fs = librosa.load(io.BytesIO(uploaded[name]), sr=None, mono=True)
    data = data.astype(float)
    return data, fs, name

# -------------------- Original H-function Filter --------------------
def h_filter_original(signal, fs, alpha=2.3, beta=1.4, gamma=0.12, delta=0.35, cutoff_freq=3800):
    n = len(signal)
    freqs = fftfreq(n, 1/fs)
    fft_vals = fft(signal)
    H = 1 / (1 + (np.abs(freqs)/cutoff_freq)**alpha)**beta
    H *= np.exp(-gamma * (np.abs(freqs)/cutoff_freq))
    H = H ** (1 + delta)
    H /= np.max(H)
    filtered_signal = np.real(ifft(fft_vals * H))
    return filtered_signal, H, freqs

# -------------------- Bandpass Filter --------------------
def bandpass_filter(signal, fs, lowcut=80, highcut=7000, order=4):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    y = filtfilt(b, a, signal)
    return y

# -------------------- Notch Filter --------------------
def notch_filter(signal, fs, freq=50.0, Q=30):
    b, a = iirnotch(freq, Q, fs)
    y = filtfilt(b, a, signal)
    return y

# -------------------- Wiener Filter --------------------
def wiener_filter(signal, mysize=29):
    return wiener(signal, mysize=mysize)

# -------------------- Wavelet Denoising --------------------
def wavelet_denoise(signal, wavelet='db8', level=4):
    coeffs = pywt.wavedec(signal, wavelet, level=level)
    sigma = np.median(np.abs(coeffs[-level])) / 0.6745
    uthresh = sigma * np.sqrt(2 * np.log(len(signal)))
    coeffs_thresh = [pywt.threshold(c, value=uthresh, mode='soft') for c in coeffs]
    return pywt.waverec(coeffs_thresh, wavelet)

# -------------------- Matched Filter --------------------
def matched_filter(noisy, reference):
    corr = correlate(noisy, reference, mode='same')
    corr /= np.max(np.abs(corr))
    return corr

# -------------------- SNR Calculation --------------------
def calculate_snr_aligned(clean, noisy):
    clean = clean - np.mean(clean)
    noisy = noisy - np.mean(noisy)
    corr = np.correlate(noisy, clean, mode='full')
    delay = corr.argmax() - (len(clean) - 1)
    if delay > 0:
        noisy_aligned = noisy[delay:]
        clean_aligned = clean[:len(noisy_aligned)]
    elif delay < 0:
        clean_aligned = clean[-delay:]
        noisy_aligned = noisy[:len(clean_aligned)]
    else:
        noisy_aligned = noisy
        clean_aligned = clean
    min_len = min(len(clean_aligned), len(noisy_aligned))
    clean_aligned = clean_aligned[:min_len]
    noisy_aligned = noisy_aligned[:min_len]
    noise = noisy_aligned - clean_aligned
    s_power = np.mean(clean_aligned**2)
    n_power = np.mean(noise**2)
    if n_power < 1e-15: return np.nan
    return 10 * np.log10(s_power / n_power)

# -------------------- Main Processing --------------------
def process_audio():
    # Upload clean & noisy audio
    clean, fs_clean, _ = load_audio("Upload CLEAN voice (.wav/.opus)")
    noisy, fs_noisy, _ = load_audio("Upload NOISY voice (.wav/.opus)")

    # Resample to same rate
    target_fs = 16000
    clean = librosa.resample(y=clean, orig_sr=fs_clean, target_sr=target_fs)
    noisy = librosa.resample(y=noisy, orig_sr=fs_noisy, target_sr=target_fs)
    fs = target_fs

    # -------------------- Apply Filters Independently --------------------
    results = {}

    results['H-filter'], _, _ = h_filter_original(noisy, fs)
    results['Bandpass'] = bandpass_filter(noisy, fs)
    results['Notch'] = notch_filter(noisy, fs)
    results['Wiener'] = wiener_filter(noisy)
    results['Wavelet'] = wavelet_denoise(noisy)
    results['Matched'] = matched_filter(noisy, clean)

    # -------------------- Evaluate SNR and Save --------------------
    snr_scores = {}
    print("\nSNR values for each filter method:")
    print("{:<20s} {:>10s}".format("Method", "SNR (dB)"))
    print("-"*32)

    for key, sig in results.items():
        # RMS normalization to match clean
        rms_clean = np.sqrt(np.mean(clean**2))
        rms_sig = np.sqrt(np.mean(sig**2))
        sig *= rms_clean / (rms_sig + 1e-10)

        # Calculate SNR
        snr = calculate_snr_aligned(clean, sig)
        snr_scores[key] = snr

        # Print SNR
        print("{:<20s} {:>10.2f}".format(key, snr))

        # Save audio
        fname = f"{key.replace(' ','_')}_denoised.wav"
        sf.write(fname, sig / np.max(np.abs(sig)) * 0.99, fs)
        files.download(fname)

    # -------------------- Best SNR --------------------
    best_method = max(snr_scores, key=snr_scores.get)
    best_signal = results[best_method]
    best_signal_norm = best_signal / np.max(np.abs(best_signal)) * 0.99
    sf.write("best_denoised_voice.wav", best_signal_norm, fs)
    print(f"\nBest method: {best_method} with SNR = {snr_scores[best_method]:.2f} dB")
    files.download("best_denoised_voice.wav")

    # -------------------- Plot All Signals --------------------
    plt.figure(figsize=(14,6))
    plt.plot(clean, alpha=0.6, label="Clean")
    plt.plot(noisy, alpha=0.3, label="Noisy")
    for key, sig in results.items():
        plt.plot(sig, alpha=0.6, label=f"{key} (SNR={snr_scores[key]:.1f} dB)")
    plt.title("Clean vs Noisy vs Filtered Audio Signals")
    plt.legend()
    plt.show()

# -------------------- Run --------------------
if __name__ == "__main__":
    process_audio()

import numpy as np
import matplotlib.pyplot as plt
import librosa
import soundfile as sf
from scipy.fft import fft, ifft, fftfreq
from scipy.signal import wiener, butter, filtfilt, iirnotch, correlate, welch
import pywt
from scipy.stats import skew, kurtosis
from google.colab import files
import io

# -------------------- Load Audio --------------------
def load_audio(prompt="Upload audio (.wav/.opus)"):
    print(prompt)
    uploaded = files.upload()
    name = list(uploaded.keys())[0]
    data, fs = librosa.load(io.BytesIO(uploaded[name]), sr=None, mono=True)
    data = data.astype(float)
    return data, fs, name

# -------------------- H-function Filter --------------------
def h_filter_original(signal, fs, alpha=2.3, beta=1.4, gamma=0.12, delta=0.35, cutoff_freq=3800):
    n = len(signal)
    freqs = fftfreq(n, 1/fs)
    fft_vals = fft(signal)
    H = 1 / (1 + (np.abs(freqs)/cutoff_freq)**alpha)**beta
    H *= np.exp(-gamma * (np.abs(freqs)/cutoff_freq))
    H = H ** (1 + delta)
    H /= np.max(H)
    filtered_signal = np.real(ifft(fft_vals * H))
    return filtered_signal, H, freqs

# -------------------- Filters --------------------
def bandpass_filter(signal, fs, lowcut=80, highcut=7000, order=4):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    y = filtfilt(b, a, signal)
    return y

def notch_filter(signal, fs, freq=50.0, Q=30):
    b, a = iirnotch(freq, Q, fs)
    y = filtfilt(b, a, signal)
    return y

def wiener_filter(signal, mysize=29):
    return wiener(signal, mysize=mysize)

def wavelet_denoise(signal, wavelet='db8', level=4):
    coeffs = pywt.wavedec(signal, wavelet, level=level)
    sigma = np.median(np.abs(coeffs[-level])) / 0.6745
    uthresh = sigma * np.sqrt(2 * np.log(len(signal)))
    coeffs_thresh = [pywt.threshold(c, value=uthresh, mode='soft') for c in coeffs]
    return pywt.waverec(coeffs_thresh, wavelet)

def matched_filter(noisy, reference):
    corr = correlate(noisy, reference, mode='same')
    corr /= np.max(np.abs(corr))
    return corr

# -------------------- SNR Calculation --------------------
def calculate_snr_aligned(clean, noisy):
    clean = clean - np.mean(clean)
    noisy = noisy - np.mean(noisy)
    corr = np.correlate(noisy, clean, mode='full')
    delay = corr.argmax() - (len(clean) - 1)
    if delay > 0:
        noisy_aligned = noisy[delay:]
        clean_aligned = clean[:len(noisy_aligned)]
    elif delay < 0:
        clean_aligned = clean[-delay:]
        noisy_aligned = noisy[:len(clean_aligned)]
    else:
        noisy_aligned = noisy
        clean_aligned = clean
    min_len = min(len(clean_aligned), len(noisy_aligned))
    clean_aligned = clean_aligned[:min_len]
    noisy_aligned = noisy_aligned[:min_len]
    noise = noisy_aligned - clean_aligned
    s_power = np.mean(clean_aligned**2)
    n_power = np.mean(noise**2)
    if n_power < 1e-15: return np.nan
    return 10 * np.log10(s_power / n_power)

# -------------------- Noise Analysis --------------------
def analyze_noise(noise, fs):
    print("\n--- Noise Analysis ---")

    # Statistics
    mean_val = np.mean(noise)
    var_val = np.var(noise)
    skew_val = skew(noise)
    kurt_val = kurtosis(noise)
    print(f"Mean: {mean_val:.4f}, Variance: {var_val:.4f}, Skewness: {skew_val:.4f}, Kurtosis: {kurt_val:.4f}")

    # PSD
    f, Pxx = welch(noise, fs=fs, nperseg=4096)
    plt.figure(figsize=(10,4))
    plt.semilogy(f, Pxx)
    plt.title("Power Spectral Density of Noise")
    plt.xlabel("Frequency [Hz]")
    plt.ylabel("PSD")
    plt.grid(True)
    plt.show()

    # Spectrogram
    D = librosa.stft(noise)
    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)
    plt.figure(figsize=(12,5))
    librosa.display.specshow(S_db, sr=fs, x_axis='time', y_axis='hz')
    plt.colorbar(format='%+2.0f dB')
    plt.title("Spectrogram of Noise")
    plt.show()

    # Simple noise classification
    psd_flatness = np.var(Pxx) / np.mean(Pxx)
    if psd_flatness < 0.5:
        n_type = "White Noise"
        suggested_filter = "Wiener / Wavelet / Bandpass"
    elif np.max(Pxx)/np.mean(Pxx) > 10:
        n_type = "Hum/Tonal Noise"
        suggested_filter = "Notch Filter"
    else:
        n_type = "Non-stationary / Environmental Noise"
        suggested_filter = "Wavelet / Wiener"

    print(f"Detected Noise Type: {n_type}")
    print(f"Suggested Filters: {suggested_filter}")
    return n_type, suggested_filter

# -------------------- Main Processing --------------------
def process_audio():
    # Upload clean & noisy audio
    clean, fs_clean, _ = load_audio("Upload CLEAN voice (.wav/.opus)")
    noisy, fs_noisy, _ = load_audio("Upload NOISY voice (.wav/.opus)")

    # Resample to same rate
    target_fs = 16000
    clean = librosa.resample(y=clean, orig_sr=fs_clean, target_sr=target_fs)
    noisy = librosa.resample(y=noisy, orig_sr=fs_noisy, target_sr=target_fs)
    fs = target_fs

    # Compute noise
    noise = noisy - clean
    analyze_noise(noise, fs)

    # -------------------- Apply Filters Independently --------------------
    results = {}
    results['H-filter'], _, _ = h_filter_original(noisy, fs)
    results['Bandpass'] = bandpass_filter(noisy, fs)
    results['Notch'] = notch_filter(noisy, fs)
    results['Wiener'] = wiener_filter(noisy)
    results['Wavelet'] = wavelet_denoise(noisy)
    results['Matched'] = matched_filter(noisy, clean)

    # -------------------- Evaluate SNR and Save --------------------
    snr_scores = {}
    print("\nSNR values for each filter method:")
    print("{:<20s} {:>10s}".format("Method", "SNR (dB)"))
    print("-"*32)

    for key, sig in results.items():
        rms_clean = np.sqrt(np.mean(clean**2))
        rms_sig = np.sqrt(np.mean(sig**2))
        sig *= rms_clean / (rms_sig + 1e-10)
        snr = calculate_snr_aligned(clean, sig)
        snr_scores[key] = snr
        print("{:<20s} {:>10.2f}".format(key, snr))
        fname = f"{key.replace(' ','_')}_denoised.wav"
        sf.write(fname, sig / np.max(np.abs(sig)) * 0.99, fs)
        files.download(fname)

    # Best SNR
    best_method = max(snr_scores, key=snr_scores.get)
    best_signal = results[best_method]
    best_signal_norm = best_signal / np.max(np.abs(best_signal)) * 0.99
    sf.write("best_denoised_voice.wav", best_signal_norm, fs)
    print(f"\nBest method: {best_method} with SNR = {snr_scores[best_method]:.2f} dB")
    files.download("best_denoised_voice.wav")

    # Plot All Signals
    plt.figure(figsize=(14,6))
    plt.plot(clean, alpha=0.6, label="Clean")
    plt.plot(noisy, alpha=0.3, label="Noisy")
    for key, sig in results.items():
        plt.plot(sig, alpha=0.6, label=f"{key} (SNR={snr_scores[key]:.1f} dB)")
    plt.title("Clean vs Noisy vs Filtered Audio Signals")
    plt.legend()
    plt.show()

# -------------------- Run --------------------
if __name__ == "__main__":
    process_audio()